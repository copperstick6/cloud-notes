{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IaaS and IaaC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrastructure   \n",
    "1. Compute consists of VMS such as EC2, Containers such as Docker\n",
    "2. Storage consists of Object Storage (S3), Non-relational Stores (DynamoDB), and Relationsl Stores (Amazon RDS, Google Cloud SQL)\n",
    "3. Networking consists of Virtual Private Cloud (VPC), Load Balancers (AWS ELB)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a service model consists of \n",
    "1. A web service accessible over HTTP\n",
    "2. Typically exposing APIs with client side tools including CLIs, SDKs, UI\n",
    "3. Multi-tenant- same service is able to support multiple users\n",
    "4. Pay as you use charging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IaaS- web service that supports resource management   \n",
    "Provisioning and Management includes Creating, updating, and managing resources. Infrastructure provisioning in the real world is done through tools that support a declarative model for provisioning and management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS CloudFormation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a template describing the infrastructure resources you want in a YAML/JSON format (this is a declarative definition)  \n",
    "Give the template to the CloudFormation web service, which takes care of provisioning all infrastructure resources defined in the template.   \n",
    "Technically Infrastructure as Code, which is a web service that works with infrastructure defined in this declarative format.  \n",
    "You express what is required, not how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of \"as-Code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Easier to understand what is being provisioned. With a block of code, it's hard to easily see what is being provisioned.\n",
    "2. Robust provisioning of Infrastructure, if a single resouce fails, it will restart\n",
    "3. Infrastructure definition templates can be shared with others.\n",
    "4. Easy to recreate defined infrastructure\n",
    "5. Easy to track infrastructure resource templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level abstractions with Infrastructure resource (Look at first paragraph)  \n",
    "Target user is person managing architecture, skills needed is understanding of resources and scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS CloudFormation (again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraction is resources, templates is the formatted file that defined the resources needed, stack is the set of resources provisioned.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Declared?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources with different properties, input/output parameters. IAM permissions are **not declared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a template reusable, CloudFormation uses input parameters and mappings. IAM has Policy Variables.  \n",
    "In order to define ordering between different resources, it is either explicitly specified or implicitly defined (through an attribute).  \n",
    "All actions are supported (CRUD)  \n",
    "Operations can be All or nothing (either creates or doesn't, and if some action fails, then you delete all previously created stuff) and partially created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top level object in CloudFormation template:  \n",
    "Resources: \n",
    "HelloBucket (Logical Name)  \n",
    "Type: AWS::S3::Bucket   \n",
    "Logical name is the name used in the template, physical name is generated by AWS and is a conbination of Logical name, stack name, and unique ID.  \n",
    "Resource properties are specified with the resource like such:   \n",
    "HelloBucket (Logical Name)  \n",
    "Type: AWS::S3::Bucket  \n",
    "Properties:   \n",
    "AccessControl: PublicRead  \n",
    "In addition, you can have multiple properties, and each property can have multiple values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CreationPolicy: Attribute when resource prevents status from reaching create complete until CloudFormation receives number of success signals or until timeout is exceeded.   \n",
    "DeletionPolicy: Attribute that allows you to preserve the state of a resource before it is deleted, done through retain policy *DeletionPolicy: Retain*   \n",
    "DependsOn - attribute that allows you to specify whether you want the creation of an attribute to follow another i.e. *DependsOn: myDB*.  \n",
    "Metadata- attribute that associated structured data with resource.  \n",
    "Intrinsic functions provided by AWS, use these in your templates to assign values to properties not available until runtime. Can be used in resource policies, outputs, metadata attributes, update policy attributes   \n",
    "Ref- in built function that takes in the logical name, outputs the physical name   \n",
    "GetAtt- gets the attributes of resource, takes in logical name of resource and name of attribute, outputs attribute value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter definition consists of type of parameter, contraints on parameter value, default value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platform and PaaS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Platform is a set of one or more infrastructure resources configured to run specific apps (i.e. Python web platform, EC2 instance configured with Python2.7 and Nginx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaaS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaaS is a web service that applies transformations on infrastructure resources to generate the required plaform, also deploy apps on the generated platform,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IaaS vs PaaS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IaaS mostly just creates the infrastructure, user then has to deal with the application deployment, but PaaS does deployment on top of infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do some of the PaaS stuff with IaaC. IaC could be good for deploying pre-built static apps, but other than that it's not good for deployment. Normally, it's used by a devops person, not for app devs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IaaC is great for pre-built apps that never change, but if it is under constant change, IaC does not have the ability to build application from source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PaaS, app developers can do production applicatino deployment. This has led to DevOps engineers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation 1: It is a functional role in which they occasionally perform Operations duties.  \n",
    "Interpretation 2: It is a set of steps/processes, and these engineers use development practices when setting up infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "App developers need to be aware of infrastructure, and should not treat it as a black box. Actual infrastructure work is still done by Operations Engineers.   \n",
    "Operations Engineers need to practice good development practices and closely work with app devs to determine production architecture and required infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaaS features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows you to build/deploy applications, provides a load balancer, DNS name connected to load balancer, ability to configure SSL Certs, scales application (manually or triggered by policies), canary deployment, and deployment without any downtime, rollbacks, and log collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web pages - static. \n",
    "Web applications - dynamic   \n",
    "Web sites - web pages + web applications.  \n",
    "Primary characteristics are dynamic content, persistent storage, API access. Uses HTTP, frameworks to make it, and is logically divided into three layers (HTML UI, Web App request handling, server logic, data access layer to DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon's PaaS, deploys web apps through source code to EC2, and beanstalk handles EC2 provisioning.   \n",
    "Application can use other AWS resources, but Beanstalk provisions a LoadBalancer for the deployed application and the app can provision a routable DNS record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Application: OS folder that contains the app source code.  \n",
    "2. Application Version: Specific version of the application code, stored on S3\n",
    "3. Environment: Application version deployed on a set of AWS resources, each environment runs a single application version\n",
    "4. Environment Tier: Tier determines whether the resources provisioned by Beanstalk would be used for deploying a backend or a web app that handles HTTP traffic\n",
    "5. Environment Configuration: determines prameters and settings of environment's resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beanstalk software that runs on each EC2 instance in an environment, has to deploy app, aggregate events, generate events, monitor logs, monitor app server, patch instance components, publish logs to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment types:\n",
    "1. Load balancing/autoscaling\n",
    "2. Single Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User policies: permissions that your IAM user needs to interact with EBS.   \n",
    "Service Role: Needed by EBS to interact with other AWS services on your behalf.  \n",
    "Instance Profile: Role and permissions granted to EC2 instance in your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBS will use the permissions given to the IAM user when creating other AWS resources, user needs FullAccess managed Policy, EBS uses user permissions to launch all resources in environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains all nevessary permissions that allows EBS to call other AWS services without user intervention, permissions that allow EBS to monitor instance and environment health and update nevironments to perform updates. A service role is created by default when creating an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWSElasticBeanstalkWebTier - Policy Statement that allows EC2 instantces in your environment to upload logs to S3, default instance profile is aws-elasticbeanstalk-ec2-role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform/Container type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software stack to run on EC2 instances provisioned as part of an environment is determined by the platform/container type of environment. This is different from Docker. We're talking about Apache Tomcat here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaaS criticisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Not able to change software stack used by application. This is changing with Docker\n",
    "2. Less control, not possible to control configuration and setting of IaaS resources. \n",
    "3. Once you use a PaaS on one vendor, it's hard to migrate to other PaaS\n",
    "4. It's costly and difficult to use when apps are being developed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All AWS resources are provisioned as a part of an environment that can be customized using a config file in the app folder. Things that can be customized  include the software stack settings on the EC2 instances, type and flavor of provisioned resources.   \n",
    ".ebextensions includes files with config files. \n",
    "Use services to define the services/processes you want started on your EC2 instances. Container commands are run after the app/web server have been set up and the application version has been extracted.   \n",
    "You can use CloudFormation snippets to customize AWS resources. This is unique to EBS. EBS can also create an RDS instance, and EBS will provide the data in environment variables that needs to be read in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker solves the problem that is it should be possible to repeatedly deploy an application whilst always getting the same result.   \n",
    "This is important, because any app that is developed and tested locally should work exactly like that in production. Applications should behave the same across different environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeatability Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It's hard to ensure that there's similarity between environment components across environments. This is usually solved by PaaS or IaC for deployment\n",
    "2. Consistency of packages and libraries across different environments is hard. This has been solved by packages, but OS-level packages is harder, so the way you do it is by packaging OS along with the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges with packaging OS is it's hard to define what OS we want, what the end result of the packaging would look like, where the App + OS would run, how to bind it to databases, and how to access the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Hosts have large capacity, so containers allow us to maximize the utilization of a host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to isolate the Dockerized OS with the host OS. Requirements are:   \n",
    "1. Root file systems of Containers should remain separate\n",
    "2. Processes that are running inside Containers should remain separate\n",
    "3. Network traffic destined for different Containers should remain separate\n",
    "4. A rouge container should not be able to affect other containers running on the host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker is a technology for packaging OS + Application.   \n",
    "It started as a technologu differentiator within PaaS called DotCloud.   \n",
    "Core Docker technology open sourced in 2013, renamed to Docker Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarative definition format that defined Base OS, any packages, where to inject app, what environment variable to set, which port the app will listen to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does Docker work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker daemon pulls down base OS image specified in the Dockerfile, which is located in the Dockerfile in the root directory.  \n",
    "Docker daemon executes each line defined in the Dockerfile on this base image. This daemon builds the final image in the form of layers, and each line in the Dockerfile causes a new diff layer to be generated over the previous layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Docker Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a docker container is `docker build -t <tag-name>`. Dockerfile needs to be present in the directory from which this command is executed   \n",
    "Execute a docker container is `docker run -d -p <host-port>:<container-port><tag-name>` -d runs Docker in detached mode, -p maps container port to host port, tag-name is the name used in the `docker build` command.   \n",
    "To see logs, you run `docker logs <container-id>`.   \n",
    "To see all running Docker containers `docker ps`.  \n",
    "To stop a docker container `docker stop <container-id>`   \n",
    "To remove a stopped Docker container `docker rm <container-id>`.   \n",
    "To remove a docker container image run `docker rmi <tag-name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of container orchestration systems, which allow you to run containers across a number of hosts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global cluster state whith multiple schedulers that maints a local copy of the global state. Each scheduler can make independent scheduling decisions. If some resource is being used by some other task, they are preempted and given to the requesting scheduler depending on job priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lessons learned is that you should allocate separate IP addresses for each container (don't separate container URLs based on port numbers allocated by the orchestration engine), Use a higher level grouping mechanism for grouping containers. When containers corresponding to one app are running together, we need a way to address them together. Kube uses Labels and label selectors and containers can be assigned labels that can be the target of operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers and Managed Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is how to bind app containers with managed services. The application can start interacting with the managed service after binding is successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue with Binding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you specify Managed Service's Connection details to the applicatino container? This is done through environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues in Binding: Authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container Authorization: Granting permissions to your application containers to perform the required action on the managed instance   \n",
    "Required permissions will depend on the type of the data store and the specific actions that your application containers need to take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues in Binding: Traffic Restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic Restriction- restricting network that can reach managed data store instance   \n",
    "You should only allow traffic that originates from the cluster where your application containers are running to reach the managed instance. Traffic from any other sources should be disallowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #1 is to manually give permissions to App container, and modify Firewall to receive traffic from container cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #2 is to automate the manual approach and modify firewall/security group of Managed Service to receive traffic only from container cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #3 is sidecar proxy container, so run a container that acts as a proxy to Managed Service, give permissions to proxy container, app communicates with proxy, and Modify firewall/security group of Managed Service instance to receive traffic only from Container cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAM enables granting access to GCP (determines who has what role for each resource).  \n",
    "Who refers to Google account, service account   \n",
    "Resources refers to project, compute engine instance, cloudSQL instances.  \n",
    "Project is the top level resource from which other resources are created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines what operations are allowed on a resource, represented as $<service>, <resource>, <verb>$, and corresponds with REST actions on a resource. Caller of REST action needs those same permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Role is a collection of permissions and cannot be assigned to users directly. Users gain permission through roles. Primitive roles are owner, editor, viewer. There are also predefined roles that give fine grained permissions that primitive roles cannot satisfy. Custom roles are roles that do not fit predefined and primitive roles, that you need to satisfy your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCP Policy Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy can be defined at any level in Resource hierarchy. \n",
    "Resources inherit the policies of parent resource.   \n",
    "If a policy is set at project level, it is inherited by all its child resources.   \n",
    "Child policies cannot restrict access granted at a higher level.   \n",
    "Effective policy at a resource = union of all policies defined at the resource and inherited policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring User Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Setup is gcloud auth login, which will open a browser window to grant permission to gcloud cli to connect to your account, token only valid for an hour.   \n",
    "Can also be configured through Service Account, in which you grant roles to it. This gives you a service account file, to which you configure gcloud CLI to use that file.   \n",
    "You can also use automated Renewal like CaaStle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional application is monolithic, all functionality in same code. This makes it super easy to develop and deploy, but the cons is that it has to be devloped by the same team in the same language, and it's hard to evolve one functionality.   \n",
    "Microservice Architecture is where you break up application functinoality into separate services accessible over HTTP.   \n",
    "Only real con is overhead when beginning development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Microservices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containerization makes it easy to package different application components, and Kubernetes makes it possible to run and scale containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with Microservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serivces discover and bind to one another through a service target port pair defined (this is in Kube).   \n",
    "If a service is failing in the architecture, you need to have robust programming of each service to assume failures could occur.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No way to define microservice boundaries, really depends on the app.   \n",
    "You usually start with a monolithic app, and you may transition this over to a microservice architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaaS vs CaaS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run/Deploy application, with the ability to rollback\n",
    "2. Bind applications to managed services like DBs\n",
    "3. Scale application instances\n",
    "4. Routing of outside requests to appropriate application instances\n",
    "5. Load balancing of incoming traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PaaSes deploy application from application source code, whereas CaaSes deploy application containers\n",
    "2. PaaSes typically provision managed service instances and then bind the application to it, whereas CaaSes mostly focus on application container deployment, but provide a mechanism for binding\n",
    "3. PaaSes lack good local development support   \n",
    "4. PaaS is more suited to monolithic stuff, whereas CaaS is suited to both microservice and monolithic\n",
    "5. PaaSes provide end to end functionality, but CaaSes require you to assemble the pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container Orchestration System developed by Google written in Golang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes Control Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asks what the desired/current state is, checks if these two is the same. If not, then make changes to make them the same (known as reconciliation action).   \n",
    "All Kubernetes Controllers execute this control loop.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Objects/Abstractions: Pod, Service, Volume, Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pod represents a unit of deployment, which contains an application container, storage resources required by the container, unique network IP address, options that govern how the container should run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pod Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl create -f greetings.yaml` This command is executed on the user machine, adn the request is received by the apiserver, which stores the YAML in etcd, which is a key value store for Google.    \n",
    "The Apiserver hands over request ot the controller manager, which runs the control loop to create the pod (basically desired state is a new pod needs to be created, it doesn't exist, so create the pod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Service defines a set of pods and a policy to access them. The set of pods target is determined by a LabelSelector. Although each pod has a unique IP address, they are not exposed unless you have a service to receieve traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Service can be exposed in different ways by specifying a type in the ServiceSpec:   \n",
    "ClusterIP: Exposes a service on an internal IP in the cluster. This service is only reachable from within the cluster.  \n",
    "NodePort: Exposes the service on the same port of each selected node in the cluster. From the outside, the service is accessbiel using a NodeIP:NodePort pair.   \n",
    "LoadBalancer: Creates an external load balancer in the underlying cloud and assigns a fixed, external IP of the Service.   \n",
    "ExternalName: Exposes the service using an arbitrary name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying a container?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Create a Pod and expose it using a service. Need a separate file for service and pod. Problem with this is that you need to manage two files, and keep track of label and selector with two different files. It's hard to create more than one pod, deploy new versions, and revert versions.   \n",
    "That's where the deployment controller comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deployment controller creates a declarative model for creating/updating pods. It's a way to expose Pods to the outside world.   \n",
    "You would use the deployment controller to declare/create new pods, scale up deployment to handle load, rollback to an earlier deployment, pause the deployment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2 for deployment: Use a deployment object. The deployment controller will create a service object for exposing the Pods defined in the deployment YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CICD using Kube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is that deployments change the IP address of the app. Keeping IP address is crucial for CICD to do stuff. The solution is to use a kubernetes ingress object, which creates a static IP address for our application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a mechanism that allows us to use the same Kube cluster for running Pods, Services, Deployments for different applications. Users interacting with one namespace do not see the content in another namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are a mechanism for selecting and accessing Kubernetes objects, and is ued by controllers for performing the reconciliation actions as a part of the Control loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a mechanism that allows pods to store data in a filesystem. A volume is a directory accessible to containers in a pod. A volume is terminated/deleted when the corresponding pod is terminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enterprises are adopting CloudComputing, because there's no investment in hardware resources, more secure, and easier/quicker to adopt agile and new tech. It's also available across the globe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enterprises are going for SaaS, which is a model that means you have software on the internet that tpeople can access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vendor lock-in (once a specific cloud is chosen, it's hard to change)\n",
    "2. Migration (how to move exiting apps to the cloud)\n",
    "3. Cloud Expertise (how to best utitlize the cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendor lock-in - use multiple clouds and OpenStack, which is open source cloud software.   \n",
    "Migration - invest in tools for cloud migration, don't migrate everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orgs build their own data centers for control, cheaper cloud costs, unique requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People are moving to multi-cloud, where you have public and private clouds. You can use tools that support Multi-Cloud\n",
    "1. FirstMile - Webapp deployment to ebs and Google App Engine\n",
    "2. Caastle - Containerized deployment on GKE and ECS\n",
    "3. CloudFoundry- PaaS that supports multiple clouds\n",
    "4. Terraform- IaS for different cloud providers\n",
    "5. Gravitant/IBM - Cloud Broker software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More people using public clouds, less people using hybrid clouds, Docker used broadly, Kube use is going down, private cloud is going up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private cloud is AWS/GCP setup in your own data center. Many tools such as vSphere, Microsoft System Center, OpenStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software for creating private and public clouds, code written in python and available on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CICD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
